library(EnvStats)
library(nortest)
library(trend)
library(outliers)
library(randtests)
library(foreach)
library(doParallel)

#' @title Variation analysis
#'
#' @description Function that calculates all the variation tests for checking whether data from a sensor seems to be
#' generated randomly, or if it contains too much noise. It calculates Coefficient of Variation, IQR, Runs test and
#' Ljung-Box statistical test.
#'
#' @param sensorData A list of numbers containing a time series
#'
#' @return List of elements that contain information about the outcomes of the calculations done.
#' @export
#'
#' @examples
#' sensorData <- sample (1:10,30,replace=TRUE)
#' variation_analysis(sensorData)
#'
#' @importFrom stats Box.test IQR
#' @importFrom randtests runs.test
#' @importFrom EnvStats cv
variation_analysis <- function (sensorData) {
  # First of all, if all values are equal, the tests fail -> Return error and all 0
  if (length(unique(sensorData))==1){
    print("Unique Value!")
    myReturnList <- list ("cv" = 0, "runs" = 0, "numRuns" = 0, "ljungBox" = 0, "IQR" = 0)
    return(myReturnList)
  }

  # Check if we have random data
  # Runs test with mean as reference (median can be used)
  myThreshold <- mean(sensorData)
  outRuns = randtests::runs.test(sensorData, threshold = myThreshold)
  runsVal <- getElement(outRuns, "p.value")
  numRunsVal <- getElement(outRuns, "runs")

  # Ljung-Box test (autocorrelation test that gives idea about white noise time-series)
  outBox = Box.test(sensorData, lag = 1, type = "Ljung")
  boxVal <- getElement(outBox, "p.value")

  # Calculate quartiles and IQR
  # outQuantile=quantile(sensorData)
  outIQR <- IQR(sensorData)

  # Calculate coefficient of variation, transforming the dataset if negative values are present
  coefVar <- -100
  minValue <- min(sensorData)
  if (minValue<0) {
    sensorData <- sensorData + abs(minValue)
  }
  coefVar <- EnvStats::cv(sensorData)

  # Prepare result of the function
  myReturnList <- list ("cv" = coefVar, "runs" = runsVal, "numRuns" = numRunsVal,
                        "ljungBox" = boxVal, "IQR" = outIQR)
  return(myReturnList)
}

#' @title Outliers analysis
#'
#' @description Function that perform several analyses to check whether data from a sensor seems to contain outliers.
#' It calculates the Grubbs test for individual outliers. Additionally, it calculates several homogeneity tests:
#' SNHT, Pettitt, Buishand R, Buishand U and Lanzante. It makes use of the transformations provided with this
#' package, as well as the outliers detector for calculating angles based on the outcomes generated by the
#' homogeneity tests' statistics.
#'
#' @param sensorData A list of numbers containing a time series
#'
#' @return List of elements that contain information about the outcomes of the calculations done.
#'
#' @export
#'
#' @examples
#' sensorData <- rnorm(150, mean=15)
#' outliers_analysis(sensorData)
#'
#' @importFrom trend br.test bu.test lanzante.test mk.test pettitt.test snh.test
#' @importFrom nortest ad.test
#' @importFrom stats shapiro.test
#' @importFrom outliers grubbs.test
outliers_analysis <- function (sensorData) {
  # First of all, if all values are equal, the tests fail -> Return error and all 0
  if (length(unique(sensorData))==1){
    print("Unique Value!")
    myReturnList <- list ("shapiro" = 1, "ad" = 1,
                          "normality" = FALSE, "trend" = "none", "outliers" = TRUE,
                          "snht" = 0, "grubbs" = 0, "pettitt" = 0, "lanzante" = 0,
                          "buishandU" = 0, "buishandRange" = 0, "grubbsEDT" = 0,
                          "snhtEDT" = 0, "pettittEDT" = 0, "lanzanteEDT" = 0,
                          "buishandREDT" = 0, "buishandUEDT" = 0,
                          "angleSNHT" = 1, "anglePettitt" = 1, "angleLanzante" = 1,
                          "angleBR" = 1, "angleBU" = 1)
    return(myReturnList)
  }

  # Remove NA and NAN values (or SNHT fails) --> Consider as outlier
  sensorData[is.na(sensorData)] <- -99.99
  sensorData[is.nan(sensorData)] <- -99.99
  #plot(sensorData, col="green")

  # Transform the data, ready to be used
  sensorDataEDT <- exp_diff(sensorData)
  sensorDataPRT <- poly_reg(sensorData)

  # Check whether there is strong trend in the data or not
  outMk = mk.test(sensorData)
  #print(outMk)
  mkStatistic <- outMk$estimates[[1]]
  mkValue <- outMk$p.value
  isTrend <- FALSE
  dataTrend <- "none"

  if (mkValue < 0.05) {
    # We identify the type of trend
    isTrend <- TRUE
    dataTrend <- "increase"
    if (mkStatistic < 0) {
      dataTrend <- "decrease"
    }
  }

  # Check normality of the data with Shapiro-Wilk
  normalityTest1 <- shapiro.test(sensorData)
  #print(normalityTest1)

  # Check normality of the data with Anderson-Darling
  normalityTest2 <- ad.test(sensorData)
  #print(normalityTest2)

  dataDistribution <- "NORMAL"
  # Normality consensus and calculate mean and variance
  normalityAgreed <- TRUE
  buishandRangeVal <- NaN
  buishandRangeValEDT <- NaN
  buishandUVal <- NaN
  buishandUValEDT <- NaN
  resAngleBR <- 0
  resAngleBU <- 0
  if (normalityTest1$p.value<0.05 | normalityTest2$p.value<0.05) {
    print("The tests reported the dataset is not normal.")
    normalityAgreed <- FALSE
  } else {
    #print("The tests reported the dataset is normal.")

    # Calculate Buishand tests
    # Calculate Buishand R with original data (necessary for angles analysis)
    resBr <- br.test(sensorData, m=3000)
    #print(resBr)
    # Calculate Buishand R with ED Transformation
    resBrEDT <- br.test(sensorDataEDT, m=3000)
    # Check angles
    brAnglesResult <- turning_points_analysis(resBr$data)
    if (any(88>=brAnglesResult$angles)){
      resAngleBR <- 1
    }
    # If there is trend, use Buishand R with PR transformation
    if (isTrend){
      resBr <- br.test(sensorDataPRT, m=3000)
    }
    buishandRangeVal <- getElement(resBr, "p.value")

    # Calculate Buishand U with original data (necessary for angles analysis)
    resBu <- bu.test(sensorData, m=3000)
    #print(resBu)
    # Calculate Buishand U with ED Transformation
    resBuEDT <- bu.test(sensorDataEDT, m=3000)
    # Check angles
    buAnglesResult <- turning_points_analysis(resBu$data)
    if (any(88>=buAnglesResult$angles)){
      resAngleBU <- 1
    }
    # If there is trend, use Buishand R with PR transformation
    if (isTrend){
      resBu <- bu.test(sensorDataPRT, m=3000)
    }
    buishandUVal <- getElement(resBu, "p.value")
  }

  # Calculate SNHT and apply angles check
  # Calculate SNHT with original data (necessary for angles analysis)
  resSNHT <- snh.test(sensorData, 3000)
  #print(resSNHT)
  # Calculate SNHT with ED Transformation
  resSNHTEDT <- snh.test(sensorDataEDT, 3000)
  #print(resSNHTEDT)
  # Check angles
  resAngleSNHT <- 0
  snhtAnglesResult <- turning_points_analysis(resSNHT$data)
  if (any(45>=snhtAnglesResult$angles)){
    resAngleSNHT <- 1
  }
  # If there is trend, use SNHT with PR transformation
  if (isTrend){
    resSNHT <- snh.test(sensorDataPRT, 3000)
  }
  SNHTVal <- getElement(resSNHT, "p.value")
  SNHTValEDT <- getElement(resSNHTEDT, "p.value")

  # Calculate Pettitt
  # Calculate Pettitt with original data (necessary for angles analysis)
  resPettitt <- pettitt.test(sensorData)
  #print(resPettitt)
  # Calculate Pettitt with ED Transformation
  resPettittEDT <- pettitt.test(sensorDataEDT)
  # Check angles
  resAnglePettitt <- 0
  pettittAnglesResult <- turning_points_analysis(resPettitt$data)
  if (any(1.3>=pettittAnglesResult$angles)){
    resAnglePettitt <- 1
  }
  # If there is trend, use Pettitt with PR transformation
  if (isTrend){
    resPettitt <- pettitt.test(sensorDataPRT)
  }
  pettittVal <- getElement(resPettitt, "p.value")
  pettittValEDT <- getElement(resPettittEDT, "p.value")

  # Calculate Lanzante
  # Calculate Lanzante with original data (necessary for angles analysis)
  resLanzante <- lanzante.test(sensorData)
  #print(resLanzante)
  # Calculate Lanzante with ED Transformation
  resLanzanteEDT <- lanzante.test(sensorDataEDT)
  # Check angles
  resAngleLanzante <- 0
  lanzanteAnglesResult <- turning_points_analysis(resLanzante$data)
  if (any(1.3>=lanzanteAnglesResult$angles)){
    resAngleLanzante <- 1
  }
  # If there is trend, use Lanzante with PR transformation
  if (isTrend){
    resLanzante <- lanzante.test(sensorDataPRT)
  }
  lanzanteVal <- getElement(resLanzante, "p.value")
  lanzanteValEDT <- getElement(resLanzanteEDT, "p.value")

  # Calculate Grubbs
  resGrubbs <- grubbs.test(sensorData)
  resGrubbsEDT <- grubbs.test(sensorDataEDT)
  #print(resGrubbs)
  grubbsVal <- getElement(resGrubbs, "p.value")
  grubbsValEDT <- getElement(resGrubbsEDT, "p.value")

  # Calculate Rosner's ESD
  #resESD <- rosnerTest(sensorData, k=7)
  #print(resESD)
  #ESDVal <- resESD$n.outliers #It fails when no outliers are detected! --> TBD

  # Check if any of them detected outliers
  detectedOutliers <- FALSE
  if (SNHTVal<0.05 | grubbsVal<0.05 | pettittVal<0.05 | lanzanteVal<0.05) {
    detectedOutliers <- TRUE
  }

  # Prepare result of the function
  myReturnList <- list ("shapiro" = normalityTest1$p.value, "ad" = normalityTest2$p.value,
                        "normality" = normalityAgreed, "trend" = dataTrend, "outliers" = detectedOutliers,
                        "snht" = SNHTVal, "grubbs" = grubbsVal, "pettitt" = pettittVal, "lanzante" = lanzanteVal,
                        "buishandU" = buishandUVal, "buishandRange" = buishandRangeVal, "grubbsEDT" = grubbsValEDT,
                        "snhtEDT" = SNHTValEDT, "pettittEDT" = pettittValEDT, "lanzanteEDT" = lanzanteValEDT,
                        "buishandREDT" = buishandRangeValEDT, "buishandUEDT" = buishandUValEDT,
                        "angleSNHT" = resAngleSNHT, "anglePettitt" = resAnglePettitt, "angleLanzante" = resAngleLanzante,
                        "angleBR" = resAngleBR, "angleBU" = resAngleBU)
  return(myReturnList)
}


#' @title Analisys of anomalies in data
#'
#' @description This function analyses a dataset by executing the algorithms for variation analysis and outliers
#' detection. Several samples are extracted from the dataset and analysed by using sliding windows, so it is
#' possible to detect anomalies as the samples are varying.
#'
#' @param sensorData A list of numbers containing a time series
#' @param windowLength Size of the samples to be generated
#' @param numSamples Number of samples to extract from the original dataset
#' @param numCores Number of cores to use to run parallel code
#'
#' @return List of elements that contain information about the outcomes of the calculations done
#' @export
#'
#' @examples
#' sensorData <- rnorm(250, mean=15)
#' anomalies_analysis(sensorData, 20, 3, 2)
#'
#' @importFrom foreach foreach "%dopar%" "%do%"
#' @importFrom doParallel registerDoParallel
#' @importFrom parallel detectCores makeCluster stopCluster
anomalies_analysis <- function (sensorData, windowLength, numSamples, numCores) {
  # Prepare the index of the samples to analyse and the number of sliding steps
  numMetrics <- length(sensorData)
  numSliding <- round (windowLength*0.10, 0)
  referenceIndexes <- sample (windowLength:(numMetrics-(numSliding-1)),numSamples,replace=F)

  # Set up the parallel environment PSOCK cluster, so it can be used in Windows and Linux
  # defaultCores <- detectCores()-2
  defaultCores <- numCores
  myCluster <- makeCluster(defaultCores, type = "PSOCK")
  registerDoParallel(cl=myCluster)
  # on.exit(stopCluster(myCluster))

  i <- 1
  fullResultLong <- foreach (i=1:numSamples, .combine = 'cbind', .packages=c("nortest", "foreach", "trend",
                                                                             "outliers", "EnvStats", "randtests",
                                                                             "ggpmisc")) %dopar% {
    currentIndex <- referenceIndexes[i]
    j <- 1
    # Prepare the sliding windows (10% sample length steps)
    partialResult <- foreach (j=1:numSliding, .combine = 'cbind') %do% {
      initialIndex <- currentIndex+j-1-windowLength+j-1
      finalIndex <- currentIndex+j-1
      sensorDataChunk <- sensorData [initialIndex:finalIndex]
      resultSlidingWindow <- outliers_analysis(sensorDataChunk)
      resultVarSlidingWindow <- variation_analysis(sensorDataChunk)

      # Extract results for outcome preparation
      shapiroVal <- getElement(resultSlidingWindow, "shapiro")
      adVal <- getElement(resultSlidingWindow, "ad")
      normalityAgreed <- getElement(resultSlidingWindow, "normality")
      dataTrend <- getElement(resultSlidingWindow, "trend")
      detectedOutliers <- getElement(resultSlidingWindow, "outliers")
      SNHTVal <- getElement(resultSlidingWindow, "snht")
      grubbsVal <- getElement(resultSlidingWindow, "grubbs")
      pettittVal <- getElement(resultSlidingWindow, "pettitt")
      lanzanteVal <- getElement(resultSlidingWindow, "lanzante")
      buishandUVal <- getElement(resultSlidingWindow, "buishandU")
      buishandRangeVal <- getElement(resultSlidingWindow, "buishandRange")
      #ESDVal <- getElement(resultSlidingWindow, "ESD")
      grubbsValEDT <- getElement(resultSlidingWindow, "grubbsEDT")
      snhtValEDT <- getElement(resultSlidingWindow, "snhtEDT")
      pettittValEDT <- getElement(resultSlidingWindow, "pettittEDT")
      lanzanteValEDT <- getElement(resultSlidingWindow, "lanzanteEDT")
      buishandRValEDT <- getElement(resultSlidingWindow, "buishandREDT")
      buishandUValEDT <- getElement(resultSlidingWindow, "buishandUEDT")
      resAngleSNHT <- getElement(resultSlidingWindow, "angleSNHT")
      resAnglePettitt <- getElement(resultSlidingWindow, "anglePettitt")
      resAngleLanzante <- getElement(resultSlidingWindow, "angleLanzante")
      resAngleBR <- getElement(resultSlidingWindow, "angleBR")
      resAngleBU <- getElement(resultSlidingWindow, "angleBU")
      resCV <- getElement(resultVarSlidingWindow, "cv")
      resRunsVal <- getElement(resultVarSlidingWindow, "runs")
      resNumRuns <- getElement(resultVarSlidingWindow, "numRuns")
      resLjung <- getElement(resultVarSlidingWindow, "ljungBox")
      resIQR <- getElement(resultVarSlidingWindow, "IQR")

      # Leave the results in a list, in memory, for combination with the other loops results
      myFullReturnList <- list("initialIndex" = initialIndex, "finalIndex" = finalIndex,
                               "shapiro" = shapiroVal, "ad" = adVal, "normality" = normalityAgreed,
                               "trend" = dataTrend, "outliers" = detectedOutliers, "snht" = SNHTVal,
                               "grubbs" = grubbsVal, "pettitt" = pettittVal, "lanzante" = lanzanteVal,
                               "buishandU" = buishandUVal, "buishandRange" = buishandRangeVal,
                               "grubbsEDT" = grubbsValEDT, "snhtEDT" = snhtValEDT, "pettittEDT" = pettittValEDT,
                               "lanzanteEDT" = lanzanteValEDT, "buishandREDT" = buishandRValEDT,
                               "buishandUEDT" = buishandUValEDT, "angleSNHT" = resAngleSNHT,
                               "anglePettitt" = resAnglePettitt, "angleLanzante" = resAngleLanzante,
                               "angleBR" = resAngleBR, "angleBU" = resAngleBU, "cv" = resCV,
                               "runs" = resRunsVal, "numRuns" = resNumRuns, "ljungBox" = resLjung, "IQR" = resIQR)
    }
  }
  stopCluster(myCluster)
}
