> failureOriginalList
 [1] 0 0 1 1 1 1 0 0 1 1 0 0 0 1 0 0 0 0 1 0
> snhtFailureList
 [1] 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 1 0
> pettittFailureList
 [1] 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1
> buishandRFailureList
 [1] 0 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0
> buishandUFailureList
 [1] 0 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0
> lanzanteFailureList
 [1] 0 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 1 1 1 1

> predictedFailures
 [1] 0 0 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0
> 
> # Calculate validation metrics
> #predictedFailures <- c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,1,1,1,1)
> #failureOriginalList <- c(1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0)
> 
> ConfusionMatrix(y_pred=predictedFailures, y_true=failureOriginalList)
      y_pred
y_true 0 1
     0 9 3
     1 0 8
> Accuracy(y_pred=predictedFailures, y_true=failureOriginalList)
[1] 0.85
> Precision(y_pred=predictedFailures, y_true=failureOriginalList, positive = "1")
[1] 0.7272727
> Recall(y_pred=predictedFailures, y_true=failureOriginalList, positive = "1")
[1] 1
> FBeta_Score(y_pred=predictedFailures, y_true=failureOriginalList, positive = "1", beta=0.5)
[1] 0.7692308
> AUC(y_pred=predictedFailures, y_true=failureOriginalList)
[1] 0.875